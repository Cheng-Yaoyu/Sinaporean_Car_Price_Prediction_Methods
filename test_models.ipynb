{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\TEMP\\ipykernel_5628\\1251424638.py:37: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_train['reg_date'] = pd.to_datetime(df_train['reg_date'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in depreciation: 201\n",
      "Missing values in omv: 29\n",
      "Missing values in arf: 65\n",
      "Missing values in depreciation: 201\n",
      "Missing values in omv: 29\n",
      "Missing values in arf: 29\n",
      "Missing values in depreciation: 201\n",
      "Missing values in omv: 29\n",
      "Missing values in arf: 29\n",
      "Missing values in depreciation: 26\n",
      "Missing values in omv: 26\n",
      "Missing values in arf: 26\n",
      "Missing values in depreciation: 9\n",
      "Missing values in omv: 13\n",
      "Missing values in arf: 13\n",
      "Missing values after filling: depreciation        0\n",
      "omv                 0\n",
      "arf                 0\n",
      "max_model_price    77\n",
      "min_model_price    77\n",
      "max_make_price      2\n",
      "min_make_price      2\n",
      "max_price           2\n",
      "min_price           2\n",
      "manufactured        3\n",
      "parf_rebate         0\n",
      "dtype: int64\n",
      "    model  indicative_price  max_price  min_price\n",
      "0   vezel      37408.189254   165800.0    14800.0\n",
      "1       3      36036.000000   168000.0     3800.0\n",
      "2  cooper     152200.500000   268800.0     7777.0\n",
      "3    vios      76286.500000   121800.0     2500.0\n",
      "4       3      26414.500000   168000.0     3800.0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 24 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   title                   10000 non-null  object \n",
      " 1   make                    10000 non-null  object \n",
      " 2   model                   10000 non-null  object \n",
      " 3   manufactured            9997 non-null   float64\n",
      " 4   type_of_vehicle         10000 non-null  object \n",
      " 5   category                10000 non-null  object \n",
      " 6   transmission            10000 non-null  object \n",
      " 7   curb_weight             9890 non-null   float64\n",
      " 8   power                   8914 non-null   float64\n",
      " 9   engine_cap              9765 non-null   float64\n",
      " 10  no_of_owners            9992 non-null   float64\n",
      " 11  depreciation            10000 non-null  float64\n",
      " 12  coe                     10000 non-null  int64  \n",
      " 13  road_tax                8918 non-null   float64\n",
      " 14  dereg_value             9917 non-null   float64\n",
      " 15  mileage                 7834 non-null   float64\n",
      " 16  omv                     10000 non-null  float64\n",
      " 17  arf                     10000 non-null  float64\n",
      " 18  indicative_price        10000 non-null  float64\n",
      " 19  remaining_years_of_coe  10000 non-null  float64\n",
      " 20  car_classification      10000 non-null  object \n",
      " 21  max_price               9998 non-null   float64\n",
      " 22  min_price               9998 non-null   float64\n",
      " 23  vehicle_age_at_dereg    9997 non-null   float64\n",
      "dtypes: float64(16), int64(1), object(7)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "df_train = pd.read_csv('train.csv')\n",
    "# df_train['reg_date'] = pd.to_datetime(df_train['reg_date'], format='%d-%b-%Y', errors='coerce')\n",
    "\n",
    "# current_year = 2024\n",
    "# current_month = 7\n",
    "\n",
    "# df_train['original_index'] = df_train.index\n",
    "\n",
    "df_train['original_depreciation'] = df_train['depreciation']\n",
    "df_train['original_omv'] = df_train['omv']\n",
    "df_train['original_arf'] = df_train['arf']\n",
    "\n",
    "def replace_make(row):\n",
    "    make = row['title'].split()[0].strip().lower() if pd.isnull(row['make']) else row['make'].lower()\n",
    "    if make == 'maybach':\n",
    "        return 'mercedes-benz'\n",
    "    else:\n",
    "        return make\n",
    "\n",
    "df_train['make'] = df_train.apply(replace_make, axis=1)\n",
    "\n",
    "def is_coe_extended(title):\n",
    "    if re.findall(r'\\(.*COE.*\\)',title):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "df_train['COE_extended'] = np.vectorize(is_coe_extended)(df_train['title'])\n",
    "\n",
    "# df_train['COE_extended'].value_counts()\n",
    "\n",
    "df_train['reg_date'] = pd.to_datetime(df_train['reg_date'])\n",
    "\n",
    "# 定义计算成熟日期的函数\n",
    "def maturity_date(coe_extended, title, reg_date):\n",
    "    if coe_extended:\n",
    "        # 如果标题中包含类似“MM/YYYY”格式的日期\n",
    "        if re.findall(r'\\d{2}/\\d{4}', title):\n",
    "            maturity_date = pd.to_datetime(re.findall(r'\\d{2}/\\d{4}', title)[0], format='%m/%Y').date()\n",
    "        else:\n",
    "            # 如果标题中没有日期信息，延长20年\n",
    "            maturity_date = (reg_date + pd.DateOffset(years=20)).date()\n",
    "    else:\n",
    "        # 如果没有延长 COE，则默认10年\n",
    "        maturity_date = (reg_date + pd.DateOffset(years=10)).date()\n",
    "    \n",
    "    return maturity_date\n",
    "\n",
    "# 使用矢量化函数来创建成熟日期列\n",
    "df_train['maturity_date'] = np.vectorize(maturity_date)(df_train['COE_extended'], df_train['title'], df_train['reg_date'])\n",
    "\n",
    "def years_left(coe_extended, reg_date, maturity_date):\n",
    "    # 计算到成熟日期的天数并转换为年\n",
    "    years_left = (pd.to_datetime(maturity_date) - pd.to_datetime('2024-06-20')).days / 365.25\n",
    "    if years_left < -1:\n",
    "        return years_left % 10\n",
    "    elif years_left < 1:\n",
    "        return 1 + years_left\n",
    "    return round(years_left, 1)\n",
    "\n",
    "# 使用矢量化函数创建剩余年份列\n",
    "df_train['remaining_years_of_coe'] = np.vectorize(years_left)(df_train['COE_extended'], df_train['reg_date'], df_train['maturity_date'])\n",
    "\n",
    "df_train.drop(columns=['COE_extended', 'maturity_date'], inplace=True)\n",
    "# df_train['years_left'].value_counts()\n",
    "\n",
    "# df_train['maturity_date'].value_counts()\n",
    "\n",
    "# df_train['remaining_years_of_coe'] = 10 - (current_year - df_train['reg_date'].dt.year + (current_month - df_train['reg_date'].dt.month) / 12) % 10\n",
    "\n",
    "def calculate_arf(omv):\n",
    "    if omv <= 20000:\n",
    "        return omv\n",
    "    elif 20000 < omv <= 40000:\n",
    "        return 20000 + 1.4 * (omv - 20000)\n",
    "    elif 40000 < omv <= 60000:\n",
    "        return 20000 + 1.4 * 20000 + 1.9 * (omv - 40000)\n",
    "    elif 60000 < omv <= 80000:\n",
    "        return 20000 + 1.4 * 20000 + 1.9 * 20000 + 2.5 * (omv - 60000)\n",
    "    else:\n",
    "        return 20000 + 1.4 * 20000 + 1.9 * 20000 + 2.5 * 20000 + 3.2 * (omv - 80000)\n",
    "\n",
    "# Function to calculate OMV based on ARF\n",
    "def calculate_omv(arf):\n",
    "    if arf <= 20000:\n",
    "        return arf\n",
    "    elif 20000 < arf <= 48000:\n",
    "        return 20000 + (arf - 20000) / 1.4\n",
    "    elif 48000 < arf <= 86000:\n",
    "        return 40000 + (arf - 48000) / 1.9\n",
    "    elif 86000 < arf <= 136000:\n",
    "        return 60000 + (arf - 86000) / 2.5\n",
    "    else:\n",
    "        return 80000 + (arf - 136000) / 3.2\n",
    "\n",
    "missing_depreciation = df_train['depreciation'].isnull().sum()\n",
    "missing_omv = df_train['omv'].isnull().sum()\n",
    "missing_arf = df_train['arf'].isnull().sum()\n",
    "\n",
    "# Print the results\n",
    "print(f'Missing values in depreciation: {missing_depreciation}')\n",
    "print(f'Missing values in omv: {missing_omv}')\n",
    "print(f'Missing values in arf: {missing_arf}')\n",
    "\n",
    "# Fill missing ARF values using OMV\n",
    "df_train['arf'] = df_train.apply(\n",
    "    lambda row: calculate_arf(row['omv']) if pd.isnull(row['arf']) and pd.notnull(row['omv']) else row['arf'], axis=1\n",
    ")\n",
    "\n",
    "# Fill missing OMV values using ARF\n",
    "df_train['omv'] = df_train.apply(\n",
    "    lambda row: calculate_omv(row['arf']) if pd.isnull(row['omv']) and pd.notnull(row['arf']) else row['omv'], axis=1\n",
    ")\n",
    "\n",
    "missing_depreciation = df_train['depreciation'].isnull().sum()\n",
    "missing_omv = df_train['omv'].isnull().sum()\n",
    "missing_arf = df_train['arf'].isnull().sum()\n",
    "\n",
    "# Print the results\n",
    "print(f'Missing values in depreciation: {missing_depreciation}')\n",
    "print(f'Missing values in omv: {missing_omv}')\n",
    "print(f'Missing values in arf: {missing_arf}')\n",
    "\n",
    "\n",
    "def fill_missing_by_title_median(df, column):\n",
    "    # Extract the first three words of the title\n",
    "    df['title_first_three'] = df['title'].apply(lambda x: ' '.join(x.split()[:3]))\n",
    "\n",
    "    for idx in df[df[column].isnull()].index:\n",
    "        current_title_first_three = df.loc[idx, 'title_first_three']\n",
    "        # Find entries with the same title_first_three\n",
    "        similar_titles = df[df['title_first_three'] == current_title_first_three]\n",
    "        if not similar_titles[column].dropna().empty:\n",
    "            # Calculate the median and fill the missing value\n",
    "            median_value = similar_titles[column].median()\n",
    "            df.loc[idx, column] = median_value\n",
    "\n",
    "    # Drop the temporary title_first_three column\n",
    "    df.drop(columns=['title_first_three'], inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "missing_depreciation = df_train['depreciation'].isnull().sum()\n",
    "missing_omv = df_train['omv'].isnull().sum()\n",
    "missing_arf = df_train['arf'].isnull().sum()\n",
    "\n",
    "# Print the results\n",
    "print(f'Missing values in depreciation: {missing_depreciation}')\n",
    "print(f'Missing values in omv: {missing_omv}')\n",
    "print(f'Missing values in arf: {missing_arf}')\n",
    "\n",
    "# Apply the function to fill missing values\n",
    "for column in ['depreciation', 'omv', 'arf']:\n",
    "    df_train = fill_missing_by_title_median(df_train, column)\n",
    "\n",
    "missing_depreciation = df_train['depreciation'].isnull().sum()\n",
    "missing_omv = df_train['omv'].isnull().sum()\n",
    "missing_arf = df_train['arf'].isnull().sum()\n",
    "\n",
    "# Print the results\n",
    "print(f'Missing values in depreciation: {missing_depreciation}')\n",
    "print(f'Missing values in omv: {missing_omv}')\n",
    "print(f'Missing values in arf: {missing_arf}')\n",
    "\n",
    "def fill_missing_by_model_mean(df, column):\n",
    "    def fill_value(group):\n",
    "        if group.notna().sum() > 0:\n",
    "            return group.fillna(group.mean())\n",
    "        else:\n",
    "            return group  # Return as is if all values are NaN\n",
    "    df[column] = df.groupby('model')[column].transform(fill_value)\n",
    "    return df\n",
    "\n",
    "# Apply the function to fill missing values\n",
    "for column in ['depreciation', 'omv', 'arf']:\n",
    "    df_train = fill_missing_by_model_mean(df_train, column)\n",
    "\n",
    "# Display the dataframe to verify\n",
    "missing_depreciation = df_train['depreciation'].isnull().sum()\n",
    "missing_omv = df_train['omv'].isnull().sum()\n",
    "missing_arf = df_train['arf'].isnull().sum()\n",
    "\n",
    "# Print the results\n",
    "print(f'Missing values in depreciation: {missing_depreciation}')\n",
    "print(f'Missing values in omv: {missing_omv}')\n",
    "print(f'Missing values in arf: {missing_arf}')\n",
    "\n",
    "# Find rows where any of the specified columns are still null\n",
    "null_models = df_train[df_train[['depreciation', 'omv', 'arf']].isnull().any(axis=1)]\n",
    "\n",
    "for column in ['depreciation', 'omv', 'arf']:\n",
    "    df_train[column] = df_train[column].fillna(df_train[column].mean())\n",
    "\n",
    "\n",
    "def classify_category(category):\n",
    "    if 'parf car' in category.lower():\n",
    "        return 'parf car'\n",
    "    elif 'coe car' in category.lower():\n",
    "        return 'coe car'\n",
    "    else:\n",
    "        return 'coe car'\n",
    "\n",
    "# Apply the classification function\n",
    "df_train['car_classification'] = df_train['category'].apply(classify_category)\n",
    "\n",
    "model_price_stats = df_train.groupby('model')['price'].agg(['max', 'min']).reset_index()\n",
    "model_price_stats.columns = ['model', 'max_model_price', 'min_model_price']\n",
    "# 用test前，需要先跑一次train，然后将上面两行要注释掉\n",
    "\n",
    "make_price_stats = df_train.groupby('make')['price'].agg(['max', 'min']).reset_index()\n",
    "make_price_stats.columns = ['make', 'max_make_price', 'min_make_price']\n",
    "# 用test前，需要先跑一次train，然后将上面两行要注释掉\n",
    "\n",
    "df_train = df_train.merge(model_price_stats, on='model', how='left')\n",
    "\n",
    "df_train = df_train.merge(make_price_stats, on='make', how='left')\n",
    "\n",
    "df_train['max_price'] = df_train['max_model_price'].combine_first(df_train['max_make_price'])\n",
    "df_train['min_price'] = df_train['min_model_price'].combine_first(df_train['min_make_price'])\n",
    "\n",
    "\n",
    "current_year = 2024\n",
    "df_train['vehicle_age_at_dereg'] = current_year - df_train['manufactured']\n",
    "\n",
    "# Function to calculate the PARF rebate\n",
    "# def calculate_parf_rebate(row):\n",
    "#     if row['vehicle_age_at_dereg'] < 5:\n",
    "#         rebate = 0.75 * row['arf']\n",
    "#     elif 5 <= row['vehicle_age_at_dereg'] < 6:\n",
    "#         rebate = 0.70 * row['arf']\n",
    "#     elif 6 <= row['vehicle_age_at_dereg'] < 7:\n",
    "#         rebate = 0.65 * row['arf']\n",
    "#     elif 7 <= row['vehicle_age_at_dereg'] < 8:\n",
    "#         rebate = 0.60 * row['arf']\n",
    "#     elif 8 <= row['vehicle_age_at_dereg'] < 9:\n",
    "#         rebate = 0.55 * row['arf']\n",
    "#     elif 9 <= row['vehicle_age_at_dereg'] < 10:\n",
    "#         rebate = 0.50 * row['arf']\n",
    "#     else:\n",
    "#         rebate = 0  # No rebate for vehicles older than 10 years\n",
    "    \n",
    "#     # Apply the cap if the car was registered on or after 15 February 2023\n",
    "#     if row['reg_date'] >= pd.Timestamp('2023-02-15'):\n",
    "#         rebate = min(rebate, 60000)\n",
    "    \n",
    "#     return rebate\n",
    "\n",
    "# # Apply the PARF rebate calculation\n",
    "# df_train['parf_rebate'] = df_train.apply(calculate_parf_rebate, axis=1)\n",
    "\n",
    "# Check for any remaining missing values\n",
    "missing_values_after = df_train[['depreciation', 'omv', 'arf', 'max_model_price', 'min_model_price', 'max_make_price', 'min_make_price', 'max_price', 'min_price', 'manufactured']].isnull().sum()\n",
    "print(f\"Missing values after filling: {missing_values_after}\")\n",
    "\n",
    "# 问题，test数据集表现不佳，可能是有一些model只有train有，需考虑是否使用make来代替\n",
    "\n",
    "def calculate_list_price(row):\n",
    "    if pd.isnull(row['remaining_years_of_coe']):\n",
    "        return None\n",
    "        \n",
    "    if row['reg_date'] >= pd.Timestamp('2013-03-01'):\n",
    "        min_parf_value = 0.5 * row['arf']\n",
    "    elif row['reg_date'] >= pd.Timestamp('2008-03-01'):\n",
    "        min_parf_value = 0.5 * row['omv'] if row['omv'] < row['arf'] else 0.5 * row['arf']\n",
    "    else:\n",
    "        min_parf_value = 0.55 * row['omv'] if row['omv'] < row['arf'] else 0.5 * row['arf']\n",
    "\n",
    "    list_price = row['depreciation'] * row['remaining_years_of_coe']\n",
    "    coe_price = row['remaining_years_of_coe'] * row['coe'] / 10\n",
    "    # parf_price = row['parf_rebate']\n",
    "    parf_price = min_parf_value\n",
    "    # if pd.notnull(row['dereg_value']):\n",
    "      # list_price += row['dereg_value']\n",
    "    # else:\n",
    "    if row['car_classification'] == 'parf car':  # assuming there's a column 'coe_vehicle' indicating COE status\n",
    "        list_price += parf_price\n",
    "      # list_price += coe_price\n",
    "\n",
    "\n",
    "    # if row['car_classification'] == 'parf car':\n",
    "    #     list_price = row['depreciation'] * row['remaining_years_of_coe'] + row['remaining_years_of_coe'] * row['coe'] / 10\n",
    "    # else:\n",
    "    #     list_price = row['depreciation'] * row['remaining_years_of_coe']\n",
    "    \n",
    "    # Adjust for COE vehicle\n",
    "        # else:\n",
    "        #     list_price += row['parf_rebate']\n",
    "    \n",
    "    # return (list_price - 450) * 0.967\n",
    "    return list_price\n",
    "\n",
    "df_train['indicative_price'] = df_train.apply(calculate_list_price, axis=1)\n",
    "\n",
    "bias = 380\n",
    "weight = 0.943\n",
    "\n",
    "\n",
    "\n",
    "# Adjust the predicted prices\n",
    "def adjust_predicted_price(row):\n",
    "    if pd.isnull(row['max_price']) or pd.isnull(row['min_price']):\n",
    "        return row['indicative_price']\n",
    "    # if pd.notnull(row['dereg_value']) and row['indicative_price'] < 1.5 * row['dereg_value']:\n",
    "    #     return 1.5 * row['dereg_value']\n",
    "    if row['indicative_price'] > row['max_price']:\n",
    "        return row['max_price']\n",
    "    elif row['indicative_price'] < row['min_price']:\n",
    "        return row['min_price']\n",
    "    else:\n",
    "        return row['indicative_price']\n",
    "\n",
    "df_train['indicative_price'] = df_train.apply(adjust_predicted_price, axis=1)\n",
    "\n",
    "\n",
    "# def calculate_used_car_price(row):\n",
    "#     used_car_price = row['omv'] * (0.15 + 0.85 * (1 - row['vehicle_age_at_dereg'] / 10)) + row['remaining_years_of_coe'] * row['coe']\n",
    "#     return used_car_price\n",
    "  \n",
    "# df_train['indicative_price'] = df_train.apply(calculate_used_car_price, axis=1)\n",
    "\n",
    "# Drop the temporary max_price and min_price columns if you don't need them\n",
    "# df_train.drop(columns=['max_price', 'min_price'], inplace=True)\n",
    "\n",
    "print(df_train[['model', 'indicative_price', 'max_price', 'min_price']].head())\n",
    "\n",
    "\n",
    "df_train.drop(columns=['listing_id', 'description', 'original_reg_date', 'reg_date', 'fuel_type', 'opc_scheme', 'lifespan', 'eco_category', 'features', 'accessories', 'original_depreciation', 'original_omv', 'original_arf', 'max_model_price', 'min_model_price', 'max_make_price', 'min_make_price'], inplace=True)\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 24 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   title                   10000 non-null  object \n",
      " 1   make                    10000 non-null  object \n",
      " 2   model                   10000 non-null  object \n",
      " 3   manufactured            10000 non-null  float64\n",
      " 4   type_of_vehicle         10000 non-null  object \n",
      " 5   category                10000 non-null  object \n",
      " 6   transmission            10000 non-null  object \n",
      " 7   curb_weight             10000 non-null  float64\n",
      " 8   power                   10000 non-null  float64\n",
      " 9   engine_cap              10000 non-null  float64\n",
      " 10  no_of_owners            10000 non-null  float64\n",
      " 11  depreciation            10000 non-null  float64\n",
      " 12  coe                     10000 non-null  int64  \n",
      " 13  road_tax                10000 non-null  float64\n",
      " 14  dereg_value             10000 non-null  float64\n",
      " 15  mileage                 10000 non-null  float64\n",
      " 16  omv                     10000 non-null  float64\n",
      " 17  arf                     10000 non-null  float64\n",
      " 18  indicative_price        10000 non-null  float64\n",
      " 19  remaining_years_of_coe  10000 non-null  float64\n",
      " 20  car_classification      10000 non-null  object \n",
      " 21  max_price               9998 non-null   float64\n",
      " 22  min_price               9998 non-null   float64\n",
      " 23  vehicle_age_at_dereg    10000 non-null  float64\n",
      "dtypes: float64(16), int64(1), object(7)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "def fill_missing_by_make_median(df, column):\n",
    "    def fill_value(group):\n",
    "        if group.notna().sum() > 0:\n",
    "            return group.fillna(group.median())\n",
    "        else:\n",
    "            return group  # Return as is if all values are NaN\n",
    "    df[column] = df.groupby('model')[column].transform(fill_value)\n",
    "    return df\n",
    "\n",
    "for column in ['manufactured', 'curb_weight', 'power', 'engine_cap', 'no_of_owners',  'road_tax', 'dereg_value', 'mileage']:\n",
    "  df_train = fill_missing_by_model_median(df_train, column)\n",
    "df_train.isnull().sum()\n",
    "\n",
    "df_train['vehicle_age_at_dereg'] = current_year - df_train['manufactured']\n",
    "\n",
    "def fill_missing_by_make_median(df, column):\n",
    "    def fill_value(group):\n",
    "        if group.notna().sum() > 0:\n",
    "            return group.fillna(group.median())\n",
    "        else:\n",
    "            return group  # Return as is if all values are NaN\n",
    "    df[column] = df.groupby('make')[column].transform(fill_value)\n",
    "    return df\n",
    "\n",
    "for column in ['curb_weight', 'power', 'engine_cap', 'no_of_owners',  'road_tax', 'dereg_value', 'mileage']:\n",
    "  df_train = fill_missing_by_make_median(df_train, column)\n",
    "df_train.isnull().sum()\n",
    "\n",
    "\n",
    "for column in ['curb_weight', 'power', 'engine_cap', 'no_of_owners',  'road_tax', 'dereg_value', 'mileage']:\n",
    "  df_train[column] = df_train[column].fillna(df_train[column].median())\n",
    "df_train.isnull().sum()\n",
    "df_train.info()\n",
    "df_train.to_csv('test_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "Mean Absolute Error: 3036.5195341249937\n",
      "Mean Squared Error: 144779723.39188203\n",
      "Root Mean Squared Error: 12032.444614120692\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import re\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# import lightgbm as lgb\n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "# from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "# from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Step 5: Encode Categorical Variables\n",
    "categorical_features = ['make', 'model', 'type_of_vehicle', 'category', 'transmission', 'car_classification']\n",
    "\n",
    "numerical_features = ['curb_weight', 'power', 'engine_cap', 'no_of_owners', 'depreciation', 'road_tax', 'dereg_value', 'mileage', 'omv', 'arf', 'indicative_price', 'remaining_years_of_coe', 'max_price', 'min_price', 'vehicle_age_at_dereg']\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "df_train = pd.read_csv('train_cleaned.csv')\n",
    "\n",
    "X = df_train.drop(columns=['title', 'manufactured', 'price'])\n",
    "y = df_train['price']\n",
    "X_preprocessed = pipeline.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Ridge(alpha=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "# model.fit(X_preprocessed, y)\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "# y_pred = model.predict(X_preprocessed)\n",
    "\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "# mae_test = mean_absolute_error(y, y_pred)\n",
    "# mse_test = mean_squared_error(y, y_pred)\n",
    "# rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "print(f'Test Set Performance:')\n",
    "print(f'Mean Absolute Error: {mae_test}')\n",
    "print(f'Mean Squared Error: {mse_test}')\n",
    "print(f'Root Mean Squared Error: {rmse_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_cleaned.csv')\n",
    "X_pred = df_test.drop(columns=['title', 'manufactured'])\n",
    "X_pred_preprocessed = pipeline.transform(X_pred)\n",
    "y_res = model.predict(X_pred_preprocessed)\n",
    "\n",
    "make_predictions = pd.DataFrame({\n",
    "    'Id': df_test.index,\n",
    "    'Predicted': y_res\n",
    "})\n",
    "\n",
    "make_predictions.to_csv('Lasso.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001681 seconds.\n",
    "You can set `force_col_wise=true` to remove the overhead.\n",
    "[LightGBM] [Info] Total Bins 3816\n",
    "[LightGBM] [Info] Number of data points in the train set: 20000, number of used features: 356\n",
    "[LightGBM] [Info] Start training from score 115632.681850\n",
    "Test Set Performance:\n",
    "Mean Absolute Error: 3485.022388617732\n",
    "Mean Squared Error: 288943707.8723001\n",
    "Root Mean Squared Error: 16998.344268554512\n",
    "\n",
    "XGBoost Regressor: \n",
    "Test Set Performance:\n",
    "Mean Absolute Error: 3796.2905301757814\n",
    "Mean Squared Error: 404668613.5832261\n",
    "Root Mean Squared Error: 20116.376750877036\n",
    "\n",
    "GradientBoostingRegressor: \n",
    "Test Set Performance:\n",
    "Mean Absolute Error: 3333.8404578557806\n",
    "Mean Squared Error: 169268452.2040934\n",
    "Root Mean Squared Error: 13010.320987742516\n",
    "\n",
    "Ridge Regression:\n",
    "Test Set Performance:\n",
    "Mean Absolute Error: 3036.5195341249937\n",
    "Mean Squared Error: 144779723.39188203\n",
    "Root Mean Squared Error: 12032.444614120692\n",
    "\n",
    "Lasso Regression:\n",
    "Test Set Performance:\n",
    "Mean Absolute Error: 3324.9121472571214\n",
    "Mean Squared Error: 154769866.71283126\n",
    "Root Mean Squared Error: 12440.653789605723"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "4347",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
